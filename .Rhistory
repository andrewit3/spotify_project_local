coverage = ans[r]
sort(p3)[n-r+1]
pHat = .92
pHat + (qnorm(.975) * sqrt((( pHat * (1 - pHat)) / 100)))
pHat - (qnorm(.975) * sqrt((( pHat * (1 - pHat)) / 100)))
prop.test(92,n = 100)
pHat = .92
pHat + (qnorm(.975) * sqrt((( pHat * (1 - pHat)) / 100)))
pHat - (qnorm(.975) * sqrt((( pHat * (1 - pHat)) / 100)))
pHat = .92
se = sqrt(pHat  * (1 - pHat)) / 100)
pHat = .92
se = sqrt((pHat  * (1 - pHat)) / 100)
pHat - (qnorm(.975) * se)
pHat + (qnorm(.975) * se)
TS = (10 * .12) / sqrt(.8 * .2 )
1 - pnorm(TS)
pHatVal = c(.75,.8,.85,.9,.95)
TSVal = (10 * (pHatVal - .8)) / sqrt(.8 * .2)
1  - pnorm(TSVal)
pHatVal = c(.75,.8,.85,.9,.95)
TSVal = (10 * (pHatVal - .8)) / sqrt(.8 * .2)
cbind(pHatVal,1  - pnorm(TSVal))
TSVal
pnorm(TSVAL)
pHatVal = c(.75,.8,.85,.9,.95)
TSVal = (10 * (pHatVal - .8)) / sqrt(.8 * .2)
pnorm(TSVaL)
pHatVal = c(.75,.8,.85,.9,.95)
TSVal = (10 * (pHatVal - .8)) / sqrt(.8 * .2)
pnorm(TSVaL)
pHatVal = c(.75,.8,.85,.9,.95)
TSVal = (10 * (pHatVal - .8)) / sqrt(.8 * .2)
pnorm(TSVal)
cbind(pHatVal,1  - pnorm(TSVal))
1 - pbinom(q = qbinom(.95,100,.8) - 1,100,p  = pHatVal)
ES.h(.8,.9)
ES.h(.9,.8)
pwr.p.test(h = ES.h(.9,.8),sig.level = .05,power = .8,n = )
pwr.p.test(h = ES.h(.9,.8),sig.level = .05,power = .8,n = ,alternative = "one.sided")
pwr.p.test(h = ES.h(.9,.8),sig.level = .05,power = .8,n = ,alternative = "greater")
pwr.p.test(h = ES.h(.8,.9),sig.level = .05,power = .8,n = ,alternative = "greater")
pwr.p.test(h = ES.h(.9,.8),sig.level = .05,power = .8,n = ,alternative = "greater")
#MC1
#MC2: C
pwr.norm.test(d = .5,n = ,sig.level = .05,power = .9,alternative = "greater")
n = 10
sigmaT <- 47.9
sigmaN <- 23.8
alpha = .05
1 - pchisq((sigmaN^2 / sigmaT^2) * qchisq(1 - alpha,n - 1),
n - 1)
alpha = .05
n = 20
po = .2
p1 = .4
pbinom(qbinom(1 - alpha,n,po) - 1,n,p1)
#MC5:A
pwr.p.test(h = ES.h(.4,.2),n = 20,sig.level = .05,power = ,alternative = "greater")
pbinom(q = qbinom(1 - alpha,n,po) - 1,size = n,prob = p1)
pbinom(q = qbinom(1 - alpha,n,po),size = n,prob = p1)
pwr.t.test(n = 15,d = .8,sig.level = .01,type = "one.sample",alternative = "greater")
c(.359,.104,.190,115.441,2.528) / sum(c(.359,.104,.190,115.441,2.528))
(c(.359,.104,.190,115.441,2.528) / sum(c(.359,.104,.190,115.441,2.528))) * 100
library(gsheet)
library(tidyverse)
library(ggpubr)
rows = c(rep(1,4),rep(2,4),rep(3,4),rep(4,4))
cols = c(rep(c(1,2,3,4),4))
# Reading data left to right, up and down
parts = c("D","C","B","A","B","A","D","C","A","B","C","D","C","D","A","B")
angles = c("0","pi/2","3pi/4","pi/4","pi/4","3pi/4","pi/2","0","pi/2","0","pi/4","3pi/4","3pi/4","pi/4","0","pi/2")
designMat <- cbind(rows,cols,parts,angles)
designMat <- as.data.frame(rbind(designMat,designMat,designMat))
groupOne = designMat %>%
mutate(parts = paste(parts,"1",sep = ""))
groupTwo = designMat %>%
mutate(parts = paste(parts,"2",sep = ""))
finalMat = rbind(groupOne,groupTwo)
g1 <- c(996.76,	1022.78,	1009.72,	1016.04,
1010.15,	1017.11,	994.97,	1022.67,
1017.77,	1007.08,	1023.14,	999.86,
1022.69,	997.13,	1019.29,	1003.22)
g2 <- c(993.57,	1020.84,	1011.84,	1016.02,
1011.16,	1018.98,	996.67,	1020.34,
1017.52,	1010.87,	1023.61,	998.13,
1022.43,	996.03,	1018.03,	1006.83)
g3 <- c(996.78,	1022.11,	1012,	1020.58,
1010.97,	1016.32,	996.15,	1022.67,
1018.96,	1007.18,	1023.72,	998.24,
1023.5,	998.41,	1016.08,	1007.4)
g4 <- c(1003.77,	996.98,	992.52,	1004.91,
991.12,	1003.98,	1009.8,	995.99,
1003.64,	993.99,	995.86,	1006.97,
995.36,	1006.64,	1005.48,	988.54)
g5 <- c(1009.39,	994.78,	990.26,	1004.85,
992.16,	1004.56,	1009.92,	995.92,
1003.22,	993.76,	997.42,	1007.94,
993.59,	1006.02,	1004.52,	989.95)
g6 <- c(1007.42,	994.17,	990.97,	1005.81,
994.22,	1003.64,	1009.96,	994.82,
1003.22,	996.37,	997.95,	1009.64,
995.21,	1006,	1003.99,	990.98)
finalMat$response = c(g1,g2,g3,g4,g5,g6)
write.csv(finalMat,file = "dataCleaned.csv")
finalMat = finalMat %>%
mutate(angles = ordered(factor(angles),levels = c("0","pi/4","pi/2","3pi/4")),
parts = ordered(factor(parts),levels = c("A1","A2","B1","B2","C1","C2","D1","D2")))
finalMat %>%
ggboxplot(x =  "angles",y = "response",color = "angles",add = "jitter") %>%
ggpar(xlab = "Angles",ylab = "Response",legend.title = "Angles",palette = "Dark2")
finalMat %>%
ggboxplot(x =  "parts",y = "response",color = "parts",add = "jitter") %>%
ggpar(xlab = "Parts",ylab = "Response",legend.title = "Parts",palette = "Dark2")
finalMat %>%
gghistogram(x = "response")
finalMat %>%
gghistogram(x = "response",color = "Navy")
finalMat %>%
gghistogram(x = "response",palette =  = "Dark2")
finalMat %>%
gghistogram(x = "response",palette = "Dark2")
finalMat %>%
gghistogram(x = "response",palette = "Dark2",fill = "Dark2")
finalMat %>%
gghistogram(x = "response",fill = "Teal")
finalMat %>%
gghistogram(x = "response",fill = "blue")
finalMat %>%
ggdensity(x = "response",fill = "blue")
finalMat %>%
gghistogram(x = "response",fill = "part")
finalMat %>%
gghistogram(x = "response",fill = "parts")
finalMat %>%
gghistogram(x = "response",fill = "parts",position = "dodge")
finalMat %>%
gghistogram(x = "response",fill = "parts",position = "stack")
finalMat %>%
gghistogram(x = "response",fill = "parts",position = "stack",palette = "Dark2")
finalMat %>%
gghistogram(x = "response")
finalMat %>%
gghistogram(x = "response",fill = "gold")
finalMat %>%
gghistogram(x = "response",fill = "Navy")
finalMat %>%
gghistogram(x = "response",fill = "Green")
finalMat %>%
gghistogram(x = "response",fill = "#1B9E77")
finalMat %>%
gghistogram(x = "response",fill = "#1B9E77",xlab = "Response",ylab = "Count")
# Plots located in the powerpoint
finalMat %>%
ggboxplot(x =  "angles",y = "response",color = "angles",add = "jitter") %>%
ggpar(xlab = "Angles",ylab = "Response",legend.title = "Angles",palette = "Dark2")
finalMat %>%
ggboxplot(x =  "parts",y = "response",color = "parts",add = "jitter") %>%
ggpar(xlab = "Parts",ylab = "Response",legend.title = "Parts",palette = "Dark2")
# Plots located in the powerpoint
par(mfrow = c(2,1))
finalMat %>%
ggboxplot(x =  "angles",y = "response",color = "angles",add = "jitter") %>%
ggpar(xlab = "Angles",ylab = "Response",legend.title = "Angles",palette = "Dark2")
finalMat %>%
ggboxplot(x =  "parts",y = "response",color = "parts",add = "jitter") %>%
ggpar(xlab = "Parts",ylab = "Response",legend.title = "Parts",palette = "Dark2")
# Plots located in the powerpoint
par(mfrow = c(1,2))
finalMat %>%
ggboxplot(x =  "angles",y = "response",color = "angles",add = "jitter") %>%
ggpar(xlab = "Angles",ylab = "Response",legend.title = "Angles",palette = "Dark2")
finalMat %>%
ggboxplot(x =  "parts",y = "response",color = "parts",add = "jitter") %>%
ggpar(xlab = "Parts",ylab = "Response",legend.title = "Parts",palette = "Dark2")
lambdaGrid            = c(.0001,.1,1,10)
interaction.depthGrid = c(4,5,6)
n.treesGrid           = c(500,1000)
resultsGrid           = array(0,dim=c(length(lambdaGrid),
length(interaction.depthGrid),
length(n.treesGrid)),
dimnames = list('lambda'=as.character(lambdaGrid),
'interaction'=as.character(interaction.depthGrid),
'n.trees'=as.character(n.treesGrid)))
resultsBoost          = list('bernoulli' = resultsGrid,
'adaboost'  = resultsGrid)
set.seed(1)
verbose = 0
Ychar   = as.character(Y) # gbm doesn't accept factor Y
misClass =function(predClass,trueClass,produceOutput=FALSE){
confusionMat = table(predClass,trueClass)
if(produceOutput){
return(1-sum(diag(confusionMat))/sum(confusionMat))
}
else{
print('misclass')
print(1-sum(diag(confusionMat))/sum(confusionMat))
print('confusion mat')
print(confusionMat)
}
}
# this can be called using:
#     (assuming you make the appropriately named test predictions)
# misClass(Yhat,Y_0)
require(randomForest)
require(gbm)
load("spam.Rdata")
train = spam$train
test  = !train
X     = spam$XdataF[train,]
X_0   = spam$XdataF[test,]
Y     = factor(spam$Y[train])
Y_0   = factor(spam$Y[test])
checkNumberItersF = function(ntrees = 5, tolParm = 1, maxIter = 10, verbose = 0){
###
# tolParm: iterations will continue until the percent decrease
#          is less than tolParm
###
misClassOut   = list()
totalTreesOut = list()
n              = nrow(X)
votes          = matrix(0,nrow=n,ncol=2)
totalTrees     = 0
iterations     = 0
misClassOld   = 1
while(iterations < maxIter){
votes[is.nan(votes)] = 0
iterations    = iterations + 1
totalTrees    = totalTrees + ntrees
if(verbose >= 2){cat('Total trees: ',totalTrees,'\n')}
outRf        = randomForest(X, Y,ntree = ntrees)
oob.times        = outRf$oob.times
votes_iterations = outRf$votes*oob.times
votes[oob.times>0,] = matrix(votes + votes_iterations,nrow=n)[oob.times>0,]
if(min(apply(votes,1,sum)) == 0){next}
Yhat          = apply(votes,1,which.max) - 1
misClassNew  = misClass(Yhat,Y,produceOutput = TRUE)
misClassOut[[iterations]]   = misClassNew
totalTreesOut[[iterations]] = totalTrees
percentChange = 100*(misClassNew - misClassOld)/misClassOld
if(verbose >= 1){cat('% change: ',percentChange,'\n')}
if(percentChange > -tolParm){break}
misClassOld = misClassNew
}
if(iterations == maxIter){
stop("too many iterations, try a larger ntrees or maxIter value")
}
return(list('misClass' = unlist(misClassOut),
'totalTree' = unlist(totalTreesOut)))
}
set.seed(1)
checkNumberIters = checkNumberItersF()
length(checkNumberIters$misClass)
ntrees = max(checkNumberIters$totalTree)
outRf  = randomForest(X, Y, ntree = ntrees, importance = T,proximity = T)
#### Answer 1.2.1 Fill in the appropriate code here to define the objects.
####              Answer the questions by using the `r objectName` syntax.
####              I'll just write the first example involving test misclassification rate
yHatTest <- predict(outRf,newdata = X_0)
confMatrix = table(yHatTest,Y_0)
testError = 1-sum(diag(confMatrix))/sum(confMatrix)
sens =  confMatrix[2,2] / sum(confMatrix[,2])
spec = confMatrix[1,1] / sum(confMatrix[,1])
prec = confMatrix[2,2] / sum(confMatrix[2,])
recl =  confMatrix[1,1] / sum(confMatrix[1,])
#### Answer 1.3.1
varImpPlot(outRf)
lambdaGrid            = c(.0001,.1,1,10)
interaction.depthGrid = c(4,5,6)
n.treesGrid           = c(500,1000)
resultsGrid           = array(0,dim=c(length(lambdaGrid),
length(interaction.depthGrid),
length(n.treesGrid)),
dimnames = list('lambda'=as.character(lambdaGrid),
'interaction'=as.character(interaction.depthGrid),
'n.trees'=as.character(n.treesGrid)))
resultsBoost          = list('bernoulli' = resultsGrid,
'adaboost'  = resultsGrid)
set.seed(1)
verbose = 0
Ychar   = as.character(Y) # gbm doesn't accept factor Y
Ychar_0 = as.character(Y_0)
for(distribution in c('bernoulli','adaboost')){
lamIter = 0
for(lambda in lambdaGrid){
lamIter = lamIter + 1
intIter = 0
for(interaction.depth in interaction.depthGrid){
intIter  = intIter + 1
treeIter = 0
for(n.trees in n.treesGrid){
treeIter = treeIter + 1
boostOut = gbm(Ychar~.,data=X,
n.trees=n.trees, interaction.depth=interaction.depth,
shrinkage=lambda, distribution = distribution)
fHat  = predict(boostOut,X_0,n.trees=n.trees)
Yhat = rep(0,nrow(X_0))
Yhat[fHat > 0] = 1
Yhat = as.factor(Yhat)
if(verbose > 0){
cat('lambda = ',lambda,' interaction.depth = ',interaction.depth, ' lambda = ',lambda,' n.trees = ',n.trees,'\n')
}
if(verbose > 1){
misClass(Yhat,Ychar_0)
}
resultsBoost[[distribution]][lamIter,intIter,treeIter] = misClass(Yhat,Ychar_0, produceOutput = TRUE)
}
}
}
}
lambdaGrid            = c(.0001,.1,1,10)
interaction.depthGrid = c(4,5,6)
n.treesGrid           = c(500,1000)
resultsGrid           = array(0,dim=c(length(lambdaGrid),
length(interaction.depthGrid),
length(n.treesGrid)),
dimnames = list('lambda'=as.character(lambdaGrid),
'interaction'=as.character(interaction.depthGrid),
'n.trees'=as.character(n.treesGrid)))
resultsBoost          = list('bernoulli' = resultsGrid,
'adaboost'  = resultsGrid)
set.seed(1)
verbose = 0
Ychar   = as.character(Y) # gbm doesn't accept factor Y
Ychar_0 = as.character(Y_0)
for(distribution in c('bernoulli','adaboost')){
lamIter = 0
for(lambda in lambdaGrid){
lamIter = lamIter + 1
intIter = 0
for(interaction.depth in interaction.depthGrid){
intIter  = intIter + 1
treeIter = 0
for(n.trees in n.treesGrid){
treeIter = treeIter + 1
boostOut = gbm(Ychar~.,data=X,
n.trees=n.trees, interaction.depth=interaction.depth,
shrinkage=lambda, distribution = distribution)
fHat  = predict(boostOut,X_0,n.trees=n.trees)
Yhat = rep(0,nrow(X_0))
Yhat[fHat > 0] = 1
Yhat = as.factor(Yhat)
if(verbose > 0){
cat('lambda = ',lambda,' interaction.depth = ',interaction.depth, ' lambda = ',lambda,' n.trees = ',n.trees,'\n')
}
if(verbose > 1){
misClass(Yhat,Ychar_0)
}
resultsBoost[[distribution]][lamIter,intIter,treeIter] = misClass(Yhat,Ychar_0, produceOutput = TRUE)
}
}
}
}
resultsBoost
cars
datasets::cars
datasets::mtcars
cars <- datasets::mtcars
cars$cyl
table(cars$cyl)
library(tidyverse)
mpg
# Test if multiple means are different
mpg %>%
ggplot(aes(x = cyl,y = cty,color = cyl)) +
geom_boxplot() +
geom_jitter()
# Test if multiple means are different
mpg %>%
ggplot(aes(x = factor(cyl),y = cty,color = cyl)) +
geom_boxplot() +
geom_jitter()
# Test if multiple means are different
mpg %>%
filter(cyl != 5)
# Test if multiple means are different
mpg %>%
filter(cyl != 5)  %>%
ggplot(aes(x = factor(cyl),y = cty,color = cyl)) +
geom_boxplot() +
geom_jitter()
# Test if multiple means are different
mpg %<>%
filter(cyl != 5)  %>%
mutate(cyl = factor(cyl))
mpg %>%
ggplot(aes(cyl,y = cty,color = cyl)) +
geom_boxplot() +
geom_jitter()
mpg %>%
ggplot(aes(cyl,y = cty,color = cyl)) +
geom_boxplot() +
geom_jitter() +
theme_minimal()
mpgAOV <- anova(cty ~ cyl,mpg)
mpgAOV <- aov(cty ~ cyl,mpg)
mpgAOV
mpgAOV <- anova(cty ~ cyl,mpg)
mpgAOV <- aov(cty ~ cyl,mpg)
summary(mpgAOV)
# Formula for SSE
# Formula FOR ssT
# Anova by hand
mpg %>%
group_by(cyl) %>%
summarise(mean(cty))
# Formula for SSE
# Formula FOR ssT
# Anova by hand
cyl means <- mpg %>%
group_by(cyl) %>%
summarise(mean(cty))
# Formula for SSE
# Formula FOR ssT
# Anova by hand
cylMeans <- mpg %>%
group_by(cyl) %>%
summarise(mean(cty))
mpg %>%
left_join(cylMeans)
# Formula for SSE
# Formula FOR ssT
# Anova by hand
cylMeans <- mpg %>%
group_by(cyl) %>%
summarise(groupMean =  mean(cty))
mpg %>%
left_join(cylMeans)
mpg %>%
left_join(cylMeans) %>%
select(groupMean)
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean)
mpg %>%
left_join(cylMeans,by = cyl) %>%
select(cty,groupMean)
# Formula for SSE
# Formula FOR ssT
# Anova by hand
cylMeans <- mpg %>%
group_by(cyl) %>%
summarise(groupMean =  mean(cty))
cylMeans
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean)
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl)
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl) %>%
mutate(ssg = (groupMean - mean(cty))^2,sse = (cty - groupMean)^2,
sst = (cty - mean(cty))^2)
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl) %>%
mutate(ssg = (groupMean - mean(cty))^2,sse = (cty - groupMean)^2,
sst = (cty - mean(cty))^2) %>%
mutate(acros(ssg:sst, ~ sum(.x)))
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl) %>%
mutate(ssg = (groupMean - mean(cty))^2,sse = (cty - groupMean)^2,
sst = (cty - mean(cty))^2) %>%
mutate(across(ssg:sst, ~ sum(.x)))
mpgAOV <- aov(cty ~ cyl,mpg)
summary(mpgAOV)
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl) %>%
mutate(ssg = (groupMean - mean(cty))^2,sse = (cty - groupMean)^2,
sst = (cty - mean(cty))^2) %>%
mutate(across(ssg:sst, ~ sum(.x))) %>%
select(ssg:sst)
mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl) %>%
mutate(ssg = (groupMean - mean(cty))^2,sse = (cty - groupMean)^2,
sst = (cty - mean(cty))^2) %>%
mutate(across(ssg:sst, ~ sum(.x))) %>%
select(ssg:sst) %>%
slice(1)
anova <- mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl) %>%
mutate(ssg = (groupMean - mean(cty))^2,sse = (cty - groupMean)^2,
sst = (cty - mean(cty))^2) %>%
mutate(across(ssg:sst, ~ sum(.x))) %>%
select(ssg:sst) %>%
slice(1)
anovaHand <- mpg %>%
left_join(cylMeans) %>%
select(cty,groupMean,cyl) %>%
mutate(ssg = (groupMean - mean(cty))^2,sse = (cty - groupMean)^2,
sst = (cty - mean(cty))^2) %>%
mutate(across(ssg:sst, ~ sum(.x))) %>%
select(ssg:sst) %>%
slice(1)
anovaHand %>%
mutate(msg =  ssg / 2,mse = sse / nrow(mpg) - 3)
anovaHand %>%
mutate(msg =  ssg / 2,mse = sse / nrow(mpg) - 3,FStat =  msg / mse)
summary(mpgAOV)
nrow(mpg)
anovaHand %>%
mutate(msg =  ssg / 2,mse = sse / (nrow(mpg) - 3),FStat =  msg / mse)
mpgLM <- lm(cty ~ cyl,mpg)
mpgLM
summary(mpgLM)
setwd("~/R Scripts/TidyModels/Practice")
